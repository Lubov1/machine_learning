{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Общая информация**\n",
    "\n",
    "**Срок сдачи:** 21 октября 2019, 08:30 \n",
    "\n",
    "**Штраф за опоздание:** по 0.5 балла за 24 часа задержки. Через 10 дней домашнее задание сгорает.\n",
    "\n",
    "При отправлении ДЗ указывайте фамилию в названии файла\n",
    "Присылать ДЗ необходимо в виде ссылки на свой github репозиторий на почту ml1.sphere@mail.ru с указанием темы в следующем формате:\n",
    "\n",
    "[ML0919, Задание 1] Фамилия Имя.\n",
    "\n",
    "Используйте данный Ipython Notebook при оформлении домашнего задания."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Штрафные баллы:**\n",
    "\n",
    "1. Невыполнение PEP8 -0.5 баллов\n",
    "2. Отсутствие фамилии в имени скрипта (скрипт должен называться по аналогии со stroykova_hw1.ipynb) -0.5 баллов\n",
    "3. Все строчки должны быть выполнены. Нужно, чтобы output команды можно было увидеть уже в git'е. В противном случае -0.5 баллов\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt;\n",
    "from sklearn import neighbors\n",
    "import seaborn as sns\n",
    "from sklearn import datasets\n",
    "from sklearn.base import ClassifierMixin\n",
    "from sklearn.datasets import fetch_mldata, fetch_20newsgroups\n",
    "\n",
    "from sklearn.neighbors.base import NeighborsBase, KNeighborsMixin, SupervisedIntegerMixin \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "%reload_ext pycodestyle_magic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Задание 1 (1 балл)\n",
    "Реализовать KNN в классе MyKNeighborsClassifier (обязательное условие: точность не ниже sklearn реализации)\n",
    "Разберитесь самостоятельно, какая мера расстояния используется в KNeighborsClassifier дефолтно и реализуйте свой алгоритм именно с этой мерой. Самостоятельно разберитесь, как считается score из KNeighborsClassifier и реализуйте аналог в своём классе. Score не должен уступать значению KNN из sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "65:1: W391 blank line at end of file\n"
     ]
    }
   ],
   "source": [
    "%%pycodestyle\n",
    "from scipy.spatial import distance\n",
    "from scipy.spatial.distance import pdist\n",
    "\n",
    "\n",
    "class MyKNeighborsClassifier(NeighborsBase, KNeighborsMixin,\n",
    "                             SupervisedIntegerMixin, ClassifierMixin):\n",
    "    X_test = []\n",
    "    y_test = []\n",
    "\n",
    "    def __init__(self, n_neighbors, algorithm='brute'):\n",
    "        self.n_neighbors = n_neighbors\n",
    "        self.algorithm = algorithm\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.X_test = np.array(X, dtype=np.uint8)\n",
    "        self.y_test = np.array(y, dtype=np.uint8)\n",
    "\n",
    "    def predict(self, X1):\n",
    "        self.c = np.array([])\n",
    "        self.t = np.array([])\n",
    "        X1 = np.array(X1)\n",
    "        Res = np.arange(X1.shape[0])\n",
    "        for f in range(X1.shape[0]):\n",
    "            X = X1[f]\n",
    "            X = X[np.newaxis, :]\n",
    "            N = np.repeat(X, self.X_test.shape[0], axis=0)\n",
    "            P = self.X_test - N\n",
    "            if self.algorithm == 'brute':\n",
    "                D = np.linalg.norm(self.X_test - N, axis=1)\n",
    "                args = D.argsort()[:self.n_neighbors]\n",
    "            else:\n",
    "                self.tree = neighbors.KDTree(self.X_test)\n",
    "                (D, args) = self.tree.query(X, k=self.n_neighbors)\n",
    "            args = args.flatten()\n",
    "            c = np.unique(self.y_test)\n",
    "            t = np.arange(c.shape[0])\n",
    "            res = 0\n",
    "            c_res = 0\n",
    "            cur_res = 0\n",
    "            for j in range(c.shape[0]):\n",
    "                for i in range(self.n_neighbors):\n",
    "                    if self.y_test[args[i]] == c[j]:\n",
    "                        cur_res += 1\n",
    "                if cur_res > res:\n",
    "                    res = cur_res\n",
    "                    c_res = j\n",
    "                t[j] = cur_res\n",
    "                cur_res = 0\n",
    "            self.c = np.append(self.c, c, axis=0)\n",
    "            self.t = np.append(self.t, t, axis=0)\n",
    "            Res[f] = c[c_res]\n",
    "        self.c = self.c.reshape(X1.shape[0], -1)\n",
    "        self.t = self.t.reshape(X1.shape[0], -1)\n",
    "        return Res\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        self.predict(X)\n",
    "        return np.array(self.t / np.sum(self.t, axis=1).reshape(-1, 1))\n",
    "\n",
    "    def score(self, X, y):\n",
    "        X = np.array(X)\n",
    "        my_sum = np.count_nonzero(np.subtract(self.predict(X), y))\n",
    "        return 1 - my_sum / X.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**IRIS**\n",
    "\n",
    "В библиотеке scikit-learn есть несколько датасетов из коробки. Один из них [Ирисы Фишера](https://ru.wikipedia.org/wiki/%D0%98%D1%80%D0%B8%D1%81%D1%8B_%D0%A4%D0%B8%D1%88%D0%B5%D1%80%D0%B0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.1, stratify=iris.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = KNeighborsClassifier(n_neighbors=2, algorithm='brute')\n",
    "my_clf = MyKNeighborsClassifier(n_neighbors=2, algorithm='brute')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train, y_train)\n",
    "my_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert abs(my_clf.score(X_test, y_test) - clf.score(X_test,y_test))<0.005, \"Score must be simillar\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 2 (0.5 балла)**\n",
    "\n",
    "Давайте попробуем добиться скорости работы на fit, predict и predict_proba сравнимой со sklearn для iris.\n",
    "Для этого используем numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.07 ms, sys: 0 ns, total: 1.07 ms\n",
      "Wall time: 1.08 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='brute', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=2, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 268 µs, sys: 7 µs, total: 275 µs\n",
      "Wall time: 88.2 µs\n"
     ]
    }
   ],
   "source": [
    "%time my_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.73 ms, sys: 42 µs, total: 5.77 ms\n",
      "Wall time: 5.23 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 2, 1, 1, 0, 0, 2, 0, 0, 1, 2, 2, 0, 2, 1])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.39 ms, sys: 4.07 ms, total: 7.46 ms\n",
      "Wall time: 7.01 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 2, 1, 1, 0, 0, 2, 0, 0, 1, 2, 2, 0, 2, 1])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time my_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 4.8 ms, total: 4.8 ms\n",
      "Wall time: 7.5 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time clf.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.85 ms, sys: 4.06 ms, total: 6.9 ms\n",
      "Wall time: 7 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time my_clf.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Задание 3 (1 балл)\n",
    "Добавьте algorithm='kd_tree' в реализацию KNN (использовать KDTree из sklearn.neighbors). Необходимо добиться скорости работы на fit,  predict и predict_proba сравнимой со sklearn для iris.\n",
    "Для этого используем numpy. Score не должен уступать значению KNN из sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = KNeighborsClassifier(n_neighbors=2, algorithm='kd_tree')\n",
    "my_clf = MyKNeighborsClassifier(n_neighbors=2, algorithm='kd_tree')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.1, stratify=iris.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.79 ms, sys: 47 µs, total: 1.84 ms\n",
      "Wall time: 1.9 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='kd_tree', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=2, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 72 µs, sys: 2 µs, total: 74 µs\n",
      "Wall time: 81.3 µs\n"
     ]
    }
   ],
   "source": [
    "%time my_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.39 ms, sys: 0 ns, total: 8.39 ms\n",
      "Wall time: 12 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([2, 1, 2, 2, 1, 0, 1, 0, 2, 0, 1, 2, 1, 0, 0])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14.5 ms, sys: 165 µs, total: 14.7 ms\n",
      "Wall time: 13.6 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([2, 1, 2, 2, 1, 0, 1, 0, 2, 0, 1, 2, 1, 0, 0])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time my_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 3.32 ms, total: 3.32 ms\n",
      "Wall time: 5.04 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time clf.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10.5 ms, sys: 0 ns, total: 10.5 ms\n",
      "Wall time: 10.6 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time my_clf.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert abs(my_clf.score(X_test, y_test) - clf.score(X_test,y_test))<0.005, \"Score must be simillar\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 4 (2.5 балла)**\n",
    "\n",
    "Рассмотрим новый датасет 20 newsgroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "newsgroups = fetch_20newsgroups(subset='train',remove=['headers','footers', 'quotes'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Переведите во всех документах все буквы в нижний регистр и замените во всех документах символы, не\n",
    "являющиеся буквами и цифрами, на пробелы. Далее разбейте текста по пробельным символам на токены(термы/слова). Удалите текста, содержащие только пробелы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    " #realize here\n",
    "# data_tok should be a list of lists of tokens for each line in data.\n",
    "data = newsgroups['data']\n",
    "target = newsgroups['target']\n",
    "\n",
    "data_tok1=[]\n",
    "data_tok2=[]\n",
    "\n",
    "\n",
    "for j in range(len(data)):\n",
    "    for i in range(len(data[j])):\n",
    "        if not (data[j][i].isalnum() or data[j][i]==' '):\n",
    "            data[j]=data[j].replace(data[j][i],' ')\n",
    "    data[j] = data[j].lower()\n",
    "    k=data[j].split(' ')\n",
    "    k = [x for x in k if x!='']\n",
    "    if k!=[]:\n",
    "        data_tok2.append(k)\n",
    "    if data[j]!='':\n",
    "        data_tok1.append(data[j])\n",
    "    else:\n",
    "        target = np.delete(target,len(data_tok1))\n",
    "\n",
    "data_tok=data_tok2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert all(isinstance(row, (list, tuple)) for row in data_tok), \"please convert each line into a list of tokens (strings)\"\n",
    "assert all(all(isinstance(tok, str) for tok in row) for row in data_tok), \"please convert each line into a list of tokens (strings)\"\n",
    "is_latin = lambda tok: all('a' <= x.lower() <= 'z' for x in tok)\n",
    "assert all(map(lambda l: not is_latin(l) or l.islower() , map(' '.join, data_tok))), \"please make sure that you lowercase the data and drop spaced texts\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Преобразуйте датасет в разреженную матрицу scipy.sparse.csr_matrix, где значение x в позиции (i, j)\n",
    "означает, что в документе i слово j встретилось x раз"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer(dtype=np.int8,min_df=30)\n",
    "X = vectorizer.fit_transform(data_tok1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Так мы получили векторное представление наших текстов. Значит можно приступать к задаче обучения модели*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуйте разбиение выборки для кросс-валидации на 3 фолдах. Разрешено использовать sklearn.cross_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7397,)\n",
      "(3699,)\n",
      "(7397,)\n",
      "(3699,)\n",
      "(7398,)\n",
      "(3698,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from  sklearn.model_selection  import  train_test_split\n",
    "kf = KFold(n_splits=3)\n",
    "for train, test in kf.split(X):\n",
    "    print(train.shape)\n",
    "    print(test.shape) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напишите метод, позволяющий найти оптимальное количество ближайших соседей(дающее максимальный score в среднем на валидации на 3 фолдах).\n",
    "Постройте график зависимости среднего score от количества соседей. Можно рассмотреть число соседей от 1 до 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как изменится качество на валидации, если:\n",
    "\n",
    "1. Используется косинусная метрика вместо евклидовой.\n",
    "2. К текстам применяется TfIdf преобразование( sklearn.feature_extraction.text.TfidfTransformer)\n",
    "\n",
    "Сравните модели, выберите лучшую."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузим  теперь test  часть нашей выборки и преобразуем её аналогично с train частью. Не забудьте, что наборы слов в train и test части могут отличаться."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newsgroups = fetch_20newsgroups(subset='test',remove=['headers','footers', 'quotes'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оценим качество(score) вашей лучшей модели на test части датасета. Отличается ли оно от кросс-валидации? Попробуйте сделать выводы, почему отличается качество."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
